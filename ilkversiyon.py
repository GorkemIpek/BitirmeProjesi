# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YaCR-K_ChSZeDdGwXAKRemnauX9DW-wS
"""

from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d emrahaydemr/gunshot-audio-dataset
!unzip gunshot-audio-dataset.zip
!kaggle datasets download -d aananehsansiam/audio-dataset-of-scream-and-non-scream
!unzip audio-dataset-of-scream-and-non-scream.zip

#Dataset çığlık ve çığlık değil şeklindeydi sadece çığlık kısmını aldık.
import os
import shutil

kaynak_klasor = '/content/Converted_Separately/scream'
hedef_klasor = '/content/Scream'

if os.path.exists(kaynak_klasor):
    shutil.move(kaynak_klasor, hedef_klasor)


converted_klasor = '/content/Converted_Separately'
if os.path.exists(converted_klasor):
    shutil.rmtree(converted_klasor)

#Bu datasette farklı silah sesleri içeriyordu hepsini bi klasörde birleştirdim.
ana_klasor = '/content/Gunshot'
os.makedirs(ana_klasor, exist_ok=True)


alt_klasorler = ['/content/AK-12', '/content/AK-47', '/content/IMI Desert Eagle', '/content/M16', '/content/M249', '/content/M4', '/content/MG-42', '/content/MP5', '/content/Zastava M92']


for alt_klasor in alt_klasorler:
    if os.path.exists(alt_klasor):

        shutil.move(alt_klasor, os.path.join(ana_klasor, os.path.basename(alt_klasor)))

#Test etmek için dosyaları eğitimden çıkardım.
kaynak_dosya_1 = '/content/Gunshot/AK-12/3 (29).wav'
hedef_dosya_1 = '/content/3 (29).wav'

if os.path.exists(kaynak_dosya_1):
    shutil.move(kaynak_dosya_1, hedef_dosya_1)

kaynak_dosya_2 = '/content/Scream/1033.wav'
hedef_dosya_2 = '/content/1033.wav'

if os.path.exists(kaynak_dosya_2):
    shutil.move(kaynak_dosya_2, hedef_dosya_2)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np
import librosa
import os
import matplotlib.pyplot as plt

# Verilerin yüklenmesi ve işlenmesi
def load_data(folders, labels):
    data = []
    valid_labels = []
    for folder, label in zip(folders, labels):
        audio_files = [f for f in os.listdir(folder) if f.endswith('.wav')]  # Sadece .wav dosyaları (gerekli olmayabilir emin değilim)
        for file in audio_files:
            file_path = os.path.join(folder, file)
            try:
                audio, sr = librosa.load(file_path, sr=None)
                audio = augment_audio(audio)  # Verileri arttırmak için.
                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)
                data.append(np.mean(mfccs.T, axis=0))  # MFCC ortalamasını al
                valid_labels.append(label)  #Etiketle
            except Exception as e:
                print(f"Hata: {e} - {file} yüklenemedi.")  # Hata nerde ?
    return np.array(data), np.array(valid_labels)  #Etiket

# Veri arttırma fonksiyonu.
def augment_audio(audio):
    noise = np.random.randn(len(audio)) * 0.005  # Gürültü ekliyoruz.
    data_noisy = audio + noise
    return data_noisy

# Klasörleri ve Verileri hazırlıyoruz.
folders = [
    '/content/Gunshot/AK-47',
    '/content/Gunshot/AK-12',
    '/content/Gunshot/IMI Desert Eagle',
    '/content/Gunshot/M16',
    '/content/Gunshot/M249',
    '/content/Gunshot/M4',
    '/content/Gunshot/MG-42',
    '/content/Gunshot/MP5',
    '/content/Gunshot/Zastava M92',
    '/content/Scream'
]

labels = [
    'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Scream'
]

# Veriyi yükle.
data, valid_labels = load_data(folders, labels)

# Etiketleri dönüştür.
if data.shape[0] != len(valid_labels):
    print("Hata: Data ve Labels boyutları eşit değil.")
else:
    le = LabelEncoder()
    valid_labels = le.fit_transform(valid_labels)

    #Eğitim ve test verisi.
    x_train, x_test, y_train, y_test = train_test_split(data, valid_labels, test_size=0.2, random_state=42)

    # Model
    model = Sequential([
        Conv1D(64, 2, activation='relu', input_shape=(40, 1)),
        MaxPooling1D(2),
        Flatten(),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(len(set(valid_labels)), activation='softmax')  # Sınıf sayısı belirleme.
    ])

    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    # Verileri uygun şekle getirme.
    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))
    x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))

    # Eğitim.
    model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test))

    # Değerlendirme.
    loss, accuracy = model.evaluate(x_test, y_test)
    print(f'Test Loss: {loss}')
    print(f'Test Accuracy: {accuracy}')

    # Ses dosyasını test etmek için fonksiyon.
    def predict_audio(file_path, model):
        audio, sr = librosa.load(file_path, sr=None)
        audio = augment_audio(audio)  # Test sırasında da arttırma yapıyoruz.
        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)
        mfccs = np.mean(mfccs.T, axis=0).reshape(1, -1, 1)  # MFCC'yi uygun şekle getiriyoruz.

        # Tahmin.
        prediction = model.predict(mfccs)
        predicted_label = np.argmax(prediction, axis=1)
        return predicted_label, audio, sr

    # Test Dosyası.
    test_file = '/content/3 (29).wav'  # Test dosyası yolu.
    predicted_class, audio, sr = predict_audio(test_file, model)
    print(f'Tahmin Edilen Sınıf: {le.inverse_transform(predicted_class)}')

    # Dalga formu grafiği.
    plt.figure(figsize=(12, 6))
    plt.plot(audio)
    plt.title('Gerçek Ses Dalga Formu')
    plt.xlabel('Zaman (örnek)')
    plt.ylabel('Genlik')
    plt.grid()
    plt.axhline(y=0, color='k', linestyle='--')
    plt.show()

    # Tahmin dalga formu grafiği.
    predicted_audio = librosa.load(test_file, sr=None)[0]

    plt.figure(figsize=(12, 6))
    plt.plot(predicted_audio)
    plt.title(f'Tahmin Edilen Ses Dalga Formu - Sınıf: {le.inverse_transform(predicted_class)[0]}')
    plt.xlabel('Zaman (örnek)')
    plt.ylabel('Genlik')
    plt.grid()
    plt.axhline(y=0, color='k', linestyle='--')
    plt.show()

#(Tekrar eğitmeden tahminde bulunmak için).
# Ses dosyasını test etmek için fonksiyon.
def predict_audio(file_path, model):
    audio, sr = librosa.load(file_path, sr=None)
    audio = augment_audio(audio)  # Test sırasında da arttırma yapıyoruz.
    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)
    mfccs = np.mean(mfccs.T, axis=0).reshape(1, -1, 1)  # MFCC'yi uygun şekle getiriyoruz.

    # Tahmin.
    prediction = model.predict(mfccs)
    predicted_label = np.argmax(prediction, axis=1)
    return predicted_label, audio, sr

# Test Dosyası.
test_file = '/content/1033.wav'  # Test dosyası yolu.
predicted_class, audio, sr = predict_audio(test_file, model)
print(f'Tahmin Edilen Sınıf: {le.inverse_transform(predicted_class)}')

# Dalga formu grafiği.
plt.figure(figsize=(12, 6))
plt.plot(audio)
plt.title('Gerçek Ses Dalga Formu')
plt.xlabel('Zaman (örnek)')
plt.ylabel('Genlik')
plt.grid()
plt.axhline(y=0, color='k', linestyle='--')
plt.show()

# Tahmin dalga formu grafiği.
predicted_audio = librosa.load(test_file, sr=None)[0]

plt.figure(figsize=(12, 6))
plt.plot(predicted_audio)
plt.title(f'Tahmin Edilen Ses Dalga Formu - Sınıf: {le.inverse_transform(predicted_class)[0]}')
plt.xlabel('Zaman (örnek)')
plt.ylabel('Genlik')
plt.grid()
plt.axhline(y=0, color='k', linestyle='--')
plt.show()