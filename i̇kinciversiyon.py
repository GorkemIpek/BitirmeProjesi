# -*- coding: utf-8 -*-
"""İkinciVersiyon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15kQ4CpRUsnoNcaDLMKFk4tqSQiTKmV7t
"""

from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d emrahaydemr/gunshot-audio-dataset
!unzip gunshot-audio-dataset.zip
!kaggle datasets download -d aananehsansiam/audio-dataset-of-scream-and-non-scream
!unzip audio-dataset-of-scream-and-non-scream.zip

#Dataset çığlık ve çığlık değil şeklindeydi sadece çığlık kısmını aldık.
import os
import shutil

kaynak_klasor = '/content/Converted_Separately/scream'
hedef_klasor = '/content/Scream'

if os.path.exists(kaynak_klasor):
    shutil.move(kaynak_klasor, hedef_klasor)


converted_klasor = '/content/Converted_Separately'
if os.path.exists(converted_klasor):
    shutil.rmtree(converted_klasor)

#Bu datasette farklı silah sesleri içeriyordu hepsini bi klasörde birleştirdim.
ana_klasor = '/content/Gunshot'
os.makedirs(ana_klasor, exist_ok=True)


alt_klasorler = ['/content/AK-12', '/content/AK-47', '/content/IMI Desert Eagle', '/content/M16', '/content/M249', '/content/M4', '/content/MG-42', '/content/MP5', '/content/Zastava M92']


for alt_klasor in alt_klasorler:
    if os.path.exists(alt_klasor):

        shutil.move(alt_klasor, os.path.join(ana_klasor, os.path.basename(alt_klasor)))

#Test etmek için dosyaları eğitimden çıkardım.
kaynak_dosya_1 = '/content/Gunshot/AK-12/3 (29).wav'
hedef_dosya_1 = '/content/3 (29).wav'

if os.path.exists(kaynak_dosya_1):
    shutil.move(kaynak_dosya_1, hedef_dosya_1)

kaynak_dosya_2 = '/content/Scream/1033.wav'
hedef_dosya_2 = '/content/1033.wav'

if os.path.exists(kaynak_dosya_2):
    shutil.move(kaynak_dosya_2, hedef_dosya_2)

"""Yapılan İyileştirmeler:
Veriyi arttırdık.
Modeli geliştirdik.
Görselleştirme eklendi.
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np
import librosa
import os
import matplotlib.pyplot as plt
import librosa.display
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Veri arttırma fonksiyonu (zaman gerilmesi, ton kaydırma, gürültü ekleme)
def augment_audio_v2(audio, sr):
    # Gürültü ekleme
    noise = np.random.randn(len(audio)) * 0.005
    audio = audio + noise

    # Zaman gerilmesi
    audio = librosa.effects.time_stretch(audio, rate=np.random.uniform(0.8, 1.2))

    # DÜZELTME: Ton kaydırma
    audio = librosa.effects.pitch_shift(y=audio, sr=sr, n_steps=np.random.randint(-2, 2))

    return audio

# Veri yükleme fonksiyonu (MFCC çıkarımı ve normalizasyon)
def load_data(folders, labels):
    data = []
    valid_labels = []
    for folder, label in zip(folders, labels):
        audio_files = [f for f in os.listdir(folder) if f.endswith('.wav')]
        for file in audio_files:
            file_path = os.path.join(folder, file)
            try:
                audio, sr = librosa.load(file_path, sr=None)
                audio = augment_audio_v2(audio, sr)  # Veri arttırma
                mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)
                mfccs = np.mean(mfccs.T, axis=0)
                mfccs = (mfccs - np.mean(mfccs)) / np.std(mfccs)  # Normalizasyon
                data.append(mfccs)
                valid_labels.append(label)
            except Exception as e:
                print(f"Hata: {e} - {file} yüklenemedi.")
    return np.array(data), np.array(valid_labels)

# Klasörleri ve etiketleri hazırlıyoruz
folders = [
    '/content/Gunshot/AK-47',
    '/content/Gunshot/AK-12',
    '/content/Gunshot/IMI Desert Eagle',
    '/content/Gunshot/M16',
    '/content/Gunshot/M249',
    '/content/Gunshot/M4',
    '/content/Gunshot/MG-42',
    '/content/Gunshot/MP5',
    '/content/Gunshot/Zastava M92',
    '/content/Scream'
]

labels = [
    'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Gunshot', 'Scream'
]

# Veriyi yükle
data, valid_labels = load_data(folders, labels)

# Etiketleri dönüştür
le = LabelEncoder()
valid_labels = le.fit_transform(valid_labels)

# Eğitim ve test verisi
x_train, x_test, y_train, y_test = train_test_split(data, valid_labels, test_size=0.2, random_state=42)

# Modeli oluşturuyoruz
model = Sequential([
    Conv1D(64, 2, activation='relu', input_shape=(40, 1), kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    BatchNormalization(),
    MaxPooling1D(2),
    Conv1D(128, 2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    BatchNormalization(),
    MaxPooling1D(2),
    Flatten(),
    Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    Dropout(0.5),
    Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    Dropout(0.5),
    Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    Dropout(0.5),
    Dense(len(set(valid_labels)), activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Veriyi uygun şekle getirme
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))

# Öğrenme oranını azaltma ve erken durdurma
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Modeli eğitme
history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test), callbacks=[early_stopping, lr_scheduler])

# Model değerlendirmesi
loss, accuracy = model.evaluate(x_test, y_test)
print(f'Test Loss: {loss}')
print(f'Test Accuracy: {accuracy}')

# Eğitim doğruluğu ve kaybı görselleştirme
plt.plot(history.history['loss'], label='Eğitim Kaybı')
plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')
plt.title('Eğitim ve Doğrulama Kaybı')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.title('Eğitim ve Doğrulama Doğruluğu')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Ses dosyasını test etmek için fonksiyon
def predict_audio(file_path, model):
    audio, sr = librosa.load(file_path, sr=None)
    audio = augment_audio_v2(audio, sr)  # Test sırasında da arttırma yapıyoruz
    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)
    mfccs = np.mean(mfccs.T, axis=0).reshape(1, -1, 1)  # MFCC'yi uygun şekle getiriyoruz

    # Tahmin
    prediction = model.predict(mfccs)
    predicted_label = np.argmax(prediction, axis=1)
    return predicted_label, audio, sr

# Test dosyasını tahmin etme
test_file = '/content/3 (29).wav'  # Test dosyası yolu
predicted_class, audio, sr = predict_audio(test_file, model)
print(f'Tahmin Edilen Sınıf: {le.inverse_transform(predicted_class)}')

# Dalga formu grafiği
plt.figure(figsize=(12, 6))
plt.plot(audio)
plt.title('Gerçek Ses Dalga Formu')
plt.xlabel('Zaman (örnek)')
plt.ylabel('Genlik')
plt.grid()
plt.axhline(y=0, color='k', linestyle='--')
plt.show()

# Tahmin dalga formu grafiği
predicted_audio = librosa.load(test_file, sr=None)[0]

plt.figure(figsize=(12, 6))
plt.plot(predicted_audio)
plt.title(f'Tahmin Edilen Ses Dalga Formu - Sınıf: {le.inverse_transform(predicted_class)[0]}')
plt.xlabel('Zaman (örnek)')
plt.ylabel('Genlik')
plt.grid()
plt.axhline(y=0, color='k', linestyle='--')
plt.show()

# Performans analizi: Konfizyon matrisi ve sınıflandırma raporu
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)

print(classification_report(y_test, y_pred_classes, target_names=le.classes_))

# Konfizyon matrisi
cm = confusion_matrix(y_test, y_pred_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

def predict_audio(file_path, model):
    try:
        # Ses yükleme ve augmentasyon (eğitimdekiyle aynı işlemler)
        audio, sr = librosa.load(file_path, sr=None)
        audio = augment_audio_v2(audio, sr)

        # MFCC çıkarımı (eğitimdeki parametrelerle aynı)
        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)
        mfccs = np.mean(mfccs.T, axis=0)
        mfccs = (mfccs - np.mean(mfccs)) / np.std(mfccs)  # Normalizasyon

        # Model için uygun şekle getirme
        mfccs = mfccs.reshape(1, mfccs.shape[0], 1)  # (1, 40, 1) şekli

        # Tahmin
        prediction = model.predict(mfccs)
        predicted_label = np.argmax(prediction, axis=1)
        return predicted_label, audio, sr

    except Exception as e:
        print(f"Hata: {e} - Dosya işlenemedi.")
        return None, None, None

# Test dosyasını tahmin etme
test_file = '/content/3 (29).wav'  # Test dosyası yolu
predicted_class, audio, sr = predict_audio(test_file, model)

if predicted_class is not None:
    print(f'Tahmin Edilen Sınıf: {le.inverse_transform(predicted_class)[0]}')

    # Dalga formu grafiği
    plt.figure(figsize=(12, 6))
    plt.plot(audio)
    plt.title(f'Test Edilen Ses - Tahmin: {le.inverse_transform(predicted_class)[0]}')
    plt.xlabel('Zaman (örnek)')
    plt.ylabel('Genlik')
    plt.grid()
    plt.axhline(y=0, color='k', linestyle='--')
    plt.show()
else:
    print("Tahmin başarısız oldu.")