# -*- coding: utf-8 -*-
"""ProjeSon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LpED4RE8697gMkmff6mz7GPFFsYyurts
"""

"""from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json"""
import kagglehub
import os
import shutil

# Adım 1: Veri setini indir
path_urbansound8k = kagglehub.dataset_download("chrisfilo/urbansound8k")
path_gunshot = kagglehub.dataset_download("emrahaydemr/gunshot-audio-dataset")
path_scream = kagglehub.dataset_download("aananehsansiam/audio-dataset-of-scream-and-non-scream")

# Adım 2: İndirilen veri setlerini /content klasörüne taşı
content_path = '/content'

# Veri setlerini taşımak
shutil.move(path_urbansound8k, os.path.join(content_path, "UrbanSound8K"))
shutil.move(path_gunshot, os.path.join(content_path, "Gunshot"))
shutil.move(path_scream, os.path.join(content_path, "ScreamData"))

# Sonuçları yazdır
print("Veri setleri /content klasörüne taşındı.")

#Dataset çığlık ve çığlık değil şeklindeydi sadece çığlık kısmını aldık.
import os
import shutil

kaynak_klasor = '/content/ScreamData/Converted_Separately/scream'
hedef_klasor = '/content/Scream'

if os.path.exists(kaynak_klasor):
    shutil.move(kaynak_klasor, hedef_klasor)


converted_klasor = '/content/Converted_Separately'
if os.path.exists(converted_klasor):
    shutil.rmtree(converted_klasor)

import pandas as pd

# CSV dosyasının yolu
csv_file_path = '/content/UrbanSound8K/UrbanSound8K.csv'

base_folder = '/content/UrbanSound8K'
# CarHorn dosyalarının taşınacağı hedef klasör
car_horn_folder = '/content/CarHorn'

# Eğer CarHorn klasörü yoksa, oluştur
if not os.path.exists(car_horn_folder):
    os.makedirs(car_horn_folder)

# CSV dosyasını pandas ile oku
df = pd.read_csv(csv_file_path)

# CarHorn sınıfındaki dosyaları filtrele
car_horn_files = df[df['class'] == 'car_horn']

# 10 fold'dan her birini kontrol et
for fold_num in range(1, 11):
    # Her fold için tam yol
    fold_folder = os.path.join(base_folder, f'fold{fold_num}')

    if not os.path.exists(fold_folder):
        print(f"Uyarı: {fold_folder} klasörü bulunamadı.")
        continue

    print(f"Processing {fold_folder}...")

    # Her bir dosya ismi için işlem yap
    for index, row in car_horn_files.iterrows():
        file_name = row['slice_file_name']
        source_file_path = os.path.join(fold_folder, file_name)

        # Dosya var mı diye kontrol et
        if os.path.exists(source_file_path):
            # Dosyayı CarHorn klasörüne taşı
            shutil.move(source_file_path, os.path.join(car_horn_folder, file_name))
            print(f"{file_name} dosyası CarHorn klasörüne taşındı.")
        else:
            print(f"{file_name} dosyası {fold_folder} klasöründe bulunamadı.")

    # Fold'daki dosyaları sil (car_horn sınıfı dışında kalan dosyalar)
    for file_name in os.listdir(fold_folder):
        # Eğer dosya car_horn sınıfında değilse, sil
        if file_name not in car_horn_files['slice_file_name'].values:
            file_to_delete = os.path.join(fold_folder, file_name)
            os.remove(file_to_delete)
            print(f"{file_name} dosyası silindi.")

shutil.rmtree('/content/ScreamData')  # urbansound8k klasörünü siliyoruz
shutil.rmtree('/content/UrbanSound8K')
shutil.rmtree('/content/sample_data')

#Bu datasette farklı silah sesleri içeriyordu hepsini bi klasörde birleştirdim.
ana_klasor = '/content/Gunshot'
os.makedirs(ana_klasor, exist_ok=True)


alt_klasorler = ['/content/AK-12', '/content/AK-47', '/content/IMI Desert Eagle', '/content/M16', '/content/M249', '/content/M4', '/content/MG-42', '/content/MP5', '/content/Zastava M92']


for alt_klasor in alt_klasorler:
    if os.path.exists(alt_klasor):

        shutil.move(alt_klasor, os.path.join(ana_klasor, os.path.basename(alt_klasor)))

ana_klasor = '/content/Gunshot'
os.makedirs(ana_klasor, exist_ok=True)

# Alt klasörler listesi (Ana klasördeki alt klasörler)
alt_klasorler = [
    'AK-12', 'AK-47', 'IMI Desert Eagle',
    'M16', 'M249', 'M4', 'MG-42',
    'MP5', 'Zastava M92'
]

# Alt klasörlerdeki .wav dosyalarını Gunshot klasörüne taşıma
for alt_klasor in alt_klasorler:
    alt_klasor_yolu = os.path.join(ana_klasor, alt_klasor)  # Alt klasörün yolu

    # Eğer alt klasör mevcutsa
    if os.path.exists(alt_klasor_yolu):
        # Klasördeki tüm .wav dosyalarını bul
        for dosya in os.listdir(alt_klasor_yolu):
            if dosya.endswith('.wav'):
                # Dosyanın tam yolu
                dosya_yolu = os.path.join(alt_klasor_yolu, dosya)
                # Hedef ana klasöre taşı
                shutil.move(dosya_yolu, os.path.join(ana_klasor, dosya))

        # Alt klasör boşsa sil
        if not os.listdir(alt_klasor_yolu):
            os.rmdir(alt_klasor_yolu)

#Test etmek için dosyaları eğitimden çıkardım.
kaynak_dosya_1 = '/content/Gunshot/3 (29).wav'
hedef_dosya_1 = '/content/3 (29).wav'

if os.path.exists(kaynak_dosya_1):
    shutil.move(kaynak_dosya_1, hedef_dosya_1)

kaynak_dosya_2 = '/content/Scream/1033.wav'
hedef_dosya_2 = '/content/1033.wav'

if os.path.exists(kaynak_dosya_2):
    shutil.move(kaynak_dosya_2, hedef_dosya_2)

kaynak_dosya_3 = '/content/CarHorn/117536-1-0-0.wav'
hedef_dosya_3 = '/content/117536-1-0-0.wav'

if os.path.exists(kaynak_dosya_3):
    shutil.move(kaynak_dosya_3, hedef_dosya_3)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np
import librosa
import os
import matplotlib.pyplot as plt

# Verilerin yüklenmesi ve işlenmesi
def load_data(folders, labels):
    data = []
    valid_labels = []
    for folder, label in zip(folders, labels):
        audio_files = [f for f in os.listdir(folder) if f.endswith('.wav')]  # Sadece .wav dosyaları
        for file in audio_files:
            file_path = os.path.join(folder, file)
            try:
                audio, sr = librosa.load(file_path, sr=None)
                features = extract_features(audio, sr)  # Özellikleri çıkar
                data.append(features)  # Özellikleri ekle
                valid_labels.append(label)  # Etiketle
            except Exception as e:
                print(f"Hata: {e} - {file} yüklenemedi.")  # Hata nerde?
    return np.array(data), np.array(valid_labels)

# Veri arttırma fonksiyonu (Gürültü ve Kaydırma)
def augment_audio(audio, sr):
    # Gürültü ekleme
    noise = np.random.randn(len(audio)) * 0.02  # Beyaz gürültü ekliyoruz.
    audio_noisy = audio + noise

    # Zaman kaydırma
    shift_ms = np.random.randint(low=-50, high=50)  # Milisaniye cinsinden rastgele kaydırma
    shift_samples = int(shift_ms * sr / 1000)
    audio_shifted = np.roll(audio_noisy, shift_samples)

    # Zaman esnetme
    if np.random.rand() > 0.5:  # %50 ihtimalle zaman esnetme
        audio_shifted = time_stretch(audio_shifted, rate=np.random.uniform(0.8, 1.2))  # Sesin hızını rastgele değiştir

    # Pitch kaydırma
    if np.random.rand() > 0.5:  # %50 ihtimalle pitch kaydırma
        audio_shifted = pitch_shift(audio_shifted, sr, n_steps=np.random.randint(-3, 3))  # Pitch kaydırma

    # Volume arttırma
    if np.random.rand() > 0.5:  # %50 ihtimalle hacim arttırma
        audio_shifted = volume_augmentation(audio_shifted, factor=np.random.uniform(0.8, 1.5))  # Sesin hacmini arttırıyoruz

    # Dinamik aralık sıkıştırma
    if np.random.rand() > 0.5:
        audio_shifted = dynamic_range_compression(audio_shifted)

    # Random crop (kesim) ekle
    if np.random.rand() > 0.5:  # %50 ihtimalle kesim
        audio_shifted = random_crop(audio_shifted, sr, duration=np.random.uniform(0.5, 1.0))  # Sesin bir kısmını kes

    return audio_shifted

# Zaman esnetme fonksiyonu
def time_stretch(audio, rate=1.2):
    return librosa.effects.time_stretch(audio, rate)

# Pitch kaydırma fonksiyonu
def pitch_shift(audio, sr, n_steps=4):
    return librosa.effects.pitch_shift(audio, sr, n_steps)

# Volume arttırma fonksiyonu
def volume_augmentation(audio, factor=1.2):
    return audio * factor

# Dinamik aralık sıkıştırma fonksiyonu
def dynamic_range_compression(audio, threshold=0.8):
    audio = np.where(audio > threshold, threshold, audio)  # Sınırlama ekleniyor
    return audio

# Rastgele kesim fonksiyonu
def random_crop(audio, sr, duration=1.0):
    max_offset = len(audio) - int(duration * sr)
    offset = np.random.randint(0, max_offset)
    return audio[offset:offset+int(duration * sr)]

# Özellikleri çıkarmak için fonksiyon
def extract_features(audio, sr):
    # MFCC
    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=80)
    mfccs = np.mean(mfccs.T, axis=0)

    # Spectral Contrast
    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)
    spectral_contrast = np.mean(spectral_contrast.T, axis=0)

    # Zero Crossing Rate
    zero_crossings = librosa.feature.zero_crossing_rate(audio)
    zero_crossings = np.mean(zero_crossings.T, axis=0)

    # Özellikleri birleştir
    features = np.hstack((mfccs, spectral_contrast, zero_crossings))

    return features

# Klasörleri ve Verileri hazırlıyoruz
folders = [
    '/content/Gunshot',
    '/content/Scream',
    '/content/CarHorn'
]

labels = [
    'Gunshot', 'Scream', 'CarHorn'
]

# Veriyi yükle
data, valid_labels = load_data(folders, labels)

# Etiketleri dönüştür
le = LabelEncoder()
valid_labels = le.fit_transform(valid_labels)

# Eğitim ve test verisi
x_train, x_test, y_train, y_test = train_test_split(data, valid_labels, test_size=0.2, random_state=42)

# Kategoriler ve dosya sayıları
class_counts = {
    'Gunshot': 850,
    'Scream': 1582,
    'CarHorn': 428
}

# Sınıf ağırlıkları: Dosya sayısına ters orantılı
total_samples = sum(class_counts.values())  # Tüm örneklerin toplamı
class_weights = {label: total_samples / count for label, count in class_counts.items()}

# Görselleştirme (isteğe bağlı)
print("Sınıf Ağırlıkları:")
print(class_weights)

# Modeli oluştur
model = Sequential([
    Conv1D(64, 2, activation='relu', input_shape=(x_train.shape[1], 1)),  # Özellik sayısını kullanıyoruz
    MaxPooling1D(2),
    BatchNormalization(),  # Batch Normalization ekledik
    Conv1D(128, 3, activation='relu'),
    MaxPooling1D(2),
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(set(valid_labels)), activation='softmax')  # Sınıf sayısı
])

# Modeli derle
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Veriyi uygun şekle getirme
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))

# Modeli eğitmek, sınıf ağırlıklarını kullanarak
model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test), class_weight=class_weights)

# Modeli değerlendirme
loss, accuracy = model.evaluate(x_test, y_test)
print(f'Test Loss: {loss}')
print(f'Test Accuracy: {accuracy}')

# Modelin performansını değerlendirmek için detaylı metrikler
from sklearn.metrics import classification_report

# Modeli test et ve sınıflar için rapor oluştur
y_pred = model.predict(x_test)
y_pred = np.argmax(y_pred, axis=1)  # Tahmin edilen sınıflar

# Sınıflar için metrikleri yazdır
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Ses dosyasını test etmek için fonksiyon
def predict_audio(file_path, model):
    audio, sr = librosa.load(file_path, sr=None)
    features = extract_features(audio, sr)  # Özellikleri çıkar
    features = features.reshape(1, -1, 1)  # Özellikleri uygun şekle getiriyoruz

    # Tahmin
    prediction = model.predict(features)
    predicted_label = np.argmax(prediction, axis=1)
    return predicted_label, audio, sr

# Ses dosyasını test etmek için fonksiyon
def predict_audio(file_path, model):
    audio, sr = librosa.load(file_path, sr=None)
    features = extract_features(audio, sr)  # Özellikleri çıkar
    features = features.reshape(1, -1, 1)  # Özellikleri uygun şekle getiriyoruz

    # Tahmin
    prediction = model.predict(features)
    predicted_label = np.argmax(prediction, axis=1)
    predicted_prob = np.max(prediction)  # En yüksek olasılık değeri
    return predicted_label, predicted_prob, prediction[0], audio, sr

# Test Dosyası
test_file = '/content/3 (29).wav'  # Test dosyası yolu
predicted_class, predicted_prob, prediction_probs, audio, sr = predict_audio(test_file, model)

# Tahmin edilen sınıf
predicted_class_label = le.inverse_transform(predicted_class)[0]
print(f'Tahmin Edilen Sınıf: {predicted_class_label}')
print(f'Tahmin Edilen Olasılık: {predicted_prob * 100:.2f}%')

# Sınıf olasılıklarını yazdır
print("\nSınıf Olasılıkları:")
for class_label, class_prob in zip(le.classes_, prediction_probs):
    print(f"{class_label}: {class_prob * 100:.2f}%")

# Dalga formu grafiği
plt.figure(figsize=(12, 6))
plt.plot(audio)
plt.title('Gerçek Ses Dalga Formu')
plt.xlabel('Zaman (örnek)')
plt.ylabel('Genlik')
plt.grid()
plt.axhline(y=0, color='k', linestyle='--')
plt.show()

# Tahmin dalga formu grafiği
predicted_audio = librosa.load(test_file, sr=None)[0]

plt.figure(figsize=(12, 6))
plt.plot(predicted_audio)
plt.title(f'Tahmin Edilen Ses Dalga Formu - Sınıf: {predicted_class_label}')
plt.xlabel('Zaman (örnek)')
plt.ylabel('Genlik')
plt.grid()
plt.axhline(y=0, color='k', linestyle='--')
plt.show()

# Test Dosyası
test_file = '/content/3 (29).wav'  # Test dosyası yolu
predicted_class, predicted_prob, prediction_probs, audio, sr = predict_audio(test_file, model)

# Tahmin edilen sınıf
predicted_class_label = le.inverse_transform(predicted_class)[0]
print(f'Tahmin Edilen Sınıf: {predicted_class_label}')
print(f'Tahmin Edilen Olasılık: {predicted_prob * 100:.2f}%')

# Sınıf olasılıklarını yazdır
print("\nSınıf Olasılıkları:")
for class_label, class_prob in zip(le.classes_, prediction_probs):
    print(f"{class_label}: {class_prob * 100:.2f}%")

# Dalga formu grafiği
plt.figure(figsize=(12, 6))
plt.plot(audio)
plt.title('Gerçek Ses Dalga Formu')
plt.xlabel('Zaman (örnek)')
plt.ylabel('Genlik')
plt.grid()
plt.axhline(y=0, color='k', linestyle='--')
plt.show()